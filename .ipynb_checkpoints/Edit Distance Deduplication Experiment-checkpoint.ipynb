{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:19:33.235387Z",
     "start_time": "2020-05-08T11:19:22.958946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from nltk import edit_distance\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:19:33.250355Z",
     "start_time": "2020-05-08T11:19:33.237349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "# df = pd.read_csv(\"cust10k.csv\", delimiter=\"|\")\n",
    "file = \"./affiliationstrings/affiliationstrings_ids.csv\"\n",
    "df = pd.read_csv(file, index_col=0)\n",
    "df.columns=[\"entityname\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:45:23.966741Z",
     "start_time": "2020-05-08T14:45:23.948768Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[8544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:19:33.260355Z",
     "start_time": "2020-05-08T11:19:33.251351Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"entityname_original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword removal and lowercase conversion\n",
    "# stop = stopwords.words(\"english\")\n",
    "# df[\"entityname\"] = df[\"entityname_original\"].apply(lambda x: \" \".join(word for word in x.lower().split(\" \") if word not in stop))\n",
    "df[\"entityname\"] = df[\"entityname_original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "NUM_GROUPS = 20\n",
    "THRESHOLD = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of groups and base of column names for results\n",
    "grouplist = [f\"Group{i}\" for i in list(range(1, NUM_GROUPS+1))]\n",
    "print(grouplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(grouplist):\n",
    "    for g in grouplist:\n",
    "        df[g] = None\n",
    "        df[f\"{g}_id1\"] = None\n",
    "        df[f\"{g}_score\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:02:28.577520Z",
     "start_time": "2020-05-08T14:02:28.570516Z"
    }
   },
   "outputs": [],
   "source": [
    "setup(grouplist) # RUN THIS FIRST!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:12:28.892218Z",
     "start_time": "2020-05-08T14:02:30.439033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run initial matching algorithm. Results will be fed to network graph later in order\n",
    "# to extract additional matches using connected components.\n",
    "for g in grouplist:\n",
    "    print(f\"Starting: {g}\")\n",
    "    print(\"=\" * 72)\n",
    "    initial = datetime.now()\n",
    "    df = df.sample(frac=1)\n",
    "    # indices of names for looping\n",
    "    list_idx = [idx for idx in df.index]\n",
    "    \n",
    "    # Loop through names\n",
    "#     num_records = 100 # restrict for debug\n",
    "#     for idx in list_idx[:num_records]: # restrict for debug\n",
    "    \n",
    "    for idx in list_idx:\n",
    "#         print(\"-\" * 72)\n",
    "        current_name = df.loc[idx]['entityname']\n",
    "#         print(f\"idx:{idx} name to compare: {current_name}\")\n",
    "        \n",
    "    \n",
    "        if df.loc[idx][g] is None:\n",
    "            idx_to_compare = list_idx[list_idx.index(idx)+1:]\n",
    "            for i in idx_to_compare:\n",
    "                if df.loc[i][g] is None:\n",
    "                    compare_name = df.loc[i][\"entityname\"]\n",
    "                    fuzz_ratio = fuzz.ratio(current_name, compare_name)\n",
    "                    fuzz_partial = fuzz.partial_ratio(current_name, compare_name)\n",
    "                    fuzz_tokensort = fuzz.token_sort_ratio(current_name, compare_name)\n",
    "                    similarity_score = max(fuzz_ratio, fuzz_partial, fuzz_tokensort) # Max of 3 different ratios\n",
    "                    if similarity_score >= THRESHOLD:\n",
    "    #                     print(f\"Similarity score:{similarity_score}\")\n",
    "                        df.loc[df.index == i, g] = current_name\n",
    "                        df.loc[df.index == i, f\"{g}_score\"] = similarity_score\n",
    "                        df.loc[df.index == i, f\"{g}_id1\"] = idx\n",
    "#         else:\n",
    "#             print(f\"{current_name} already matched. Skipping.\")\n",
    "    \n",
    "    final = datetime.now()\n",
    "    total_time = final - initial\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"Group {g} total time: {total_time}\")\n",
    "\n",
    "print(\"Saving groups...\")\n",
    "df.to_csv(\"edit_dist_dedup_groups.csv\")\n",
    "print(\"Save complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:37:35.842510Z",
     "start_time": "2020-05-08T14:37:35.832549Z"
    }
   },
   "outputs": [],
   "source": [
    "# group = grouplist[0]\n",
    "# print(f\"Number of matches: {df[group].value_counts().sum()}\")\n",
    "# print(f\"Number of groups: {len(df[group].unique())}\")\n",
    "# df[group].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df[\"entityname\"].str.contains(\"AT&T\")].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate permutations of tuples:\n",
    "\n",
    "https://stackoverflow.com/questions/15352995/removing-permutations-from-a-list-of-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_temp = []\n",
    "for g in grouplist:\n",
    "    matches_temp += list(zip(df[f\"{g}_id1\"].index, df[f\"{g}_id1\"].values))\n",
    "matches_temp = list(set(matches_temp))\n",
    "\n",
    "matches = []\n",
    "for m in matches_temp:\n",
    "    if m[0] is not None and m[1] is not None:\n",
    "        matches.append(m)\n",
    "\n",
    "# Remove permutation duplicates\n",
    "matches = list(set(tuple(sorted(t)) for t in matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACED BY CODE ABOVE - DELETE IF ABOVE CODE WORKING\n",
    "# matches_temp = list(set(list(zip(df[\"GroupA_id1\"].index, df[\"GroupA_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupB_id1\"].index, df[\"GroupB_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupC_id1\"].index, df[\"GroupC_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupD_id1\"].index, df[\"GroupD_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupE_id1\"].index, df[\"GroupE_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupF_id1\"].index, df[\"GroupF_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupG_id1\"].index, df[\"GroupG_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupH_id1\"].index, df[\"GroupH_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupI_id1\"].index, df[\"GroupI_id1\"].values)) + \\\n",
    "#         list(zip(df[\"GroupJ_id1\"].index, df[\"GroupJ_id1\"].values))))\n",
    "\n",
    "# matches = []\n",
    "# for m in matches_temp:\n",
    "#     if m[0] is not None and m[1] is not None:\n",
    "#         matches.append(m)\n",
    "\n",
    "# # Remove permutation duplicates\n",
    "# matches = list(set(tuple(sorted(t)) for t in matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.DataFrame(matches)\n",
    "df_matches.columns = [\"entityid1\", \"entityid2\"]\n",
    "# df_matches.set_index(\"entityid1\", inplace=True)\n",
    "df_matches[\"match_string\"] = df_matches.apply(lambda row: str(row[\"entityid1\"])+\"|\"+str(row[\"entityid2\"]), axis=1)\n",
    "df_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ground truth\n",
    "file = \"./affiliationstrings/affiliationstrings_mapping.csv\"\n",
    "df_truth = pd.read_csv(file, index_col=0, header=None, names=[\"entityid1\", \"entityid2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_tuples = list(df_truth.reset_index().to_records(index=False))\n",
    "truth_unique = list(set(tuple(sorted(t)) for t in truth_tuples))\n",
    "truth_unique[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truth_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truthunique = pd.DataFrame(truth_unique)\n",
    "df_truthunique.columns = [\"entityid1\", \"entityid2\"]\n",
    "# df_truthunique.set_index(\"entityid1\", inplace=True)\n",
    "df_truthunique[\"match_string\"] = df_truthunique.apply(lambda row: str(row[\"entityid1\"])+\"|\"+str(row[\"entityid2\"]), axis=1)\n",
    "df_truthunique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_list = list(df_matches[\"match_string\"])\n",
    "truth_list = list(df_truthunique[\"match_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches = []\n",
    "for m in matches_list:\n",
    "    if m in truth_list:\n",
    "        good_matches.append(\"Good match\")\n",
    "    else:\n",
    "        good_matches.append(\"Bad match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches[\"GoodBad\"] = good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches[\"GoodBad\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_truth = []\n",
    "for m in truth_list:\n",
    "    if m in matches_list:\n",
    "        found_truth.append(\"Found\")\n",
    "    else:\n",
    "        found_truth.append(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truthunique[\"Found\"] = found_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truthunique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truthunique[\"Found\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use NetworkX to generate connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15), facecolor=\"black\")\n",
    "ax = nx.draw_networkx(G,\n",
    "                      with_labels=True,\n",
    "                      node_size=1,\n",
    "                      alpha=1,\n",
    "                      pos=nx.kamada_kawai_layout(G),\n",
    "#                       pos=nx.spring_layout(G),\n",
    "                      edge_color=\"silver\",\n",
    "                      node_color=\"silver\",\n",
    "                     font_size=12,\n",
    "                     font_color=\"white\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Matches - Connected Components\", fontsize=20, color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print pair of entities\n",
    "\n",
    "# Examples of not found:\n",
    "#  ['3460|6963',\n",
    "#  '1808|4095',\n",
    "#  '3265|9562',\n",
    "#  '2551|5771',\n",
    "#  '6605|7876',\n",
    "#  '3842|9044',\n",
    "#  '4208|9532',\n",
    "#  '9136|9376',\n",
    "#  '2927|8872',\n",
    "#  '7867|8584']\n",
    "print(df.loc[3460][\"entityname\"])\n",
    "print(df.loc[6963][\"entityname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current score for a pair that was not found\n",
    "testname1 = \"University of Oxford\"\n",
    "testname2 = \"Oxford University\"\n",
    "fuzz_ratio = fuzz.ratio(testname1, testname2)\n",
    "fuzz_partial = fuzz.partial_ratio(testname1, testname2)\n",
    "fuzz_tokensort = fuzz.token_sort_ratio(testname1, testname2)\n",
    "similarity_score = max(fuzz_ratio, fuzz_partial, fuzz_tokensort)\n",
    "\n",
    "print(f\"fuzz: {fuzz_ratio}, partial: {fuzz_partial}, tokensort: {fuzz_tokensort}, similarity_score: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected component subgraphs\n",
    "cc_subgraphs = list(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cc_subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(cc_subgraphs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all matching pairs based on connected components\n",
    "match_pairs = []\n",
    "for subgraph in cc_subgraphs:\n",
    "    cc = list(subgraph)\n",
    "    cc.sort()\n",
    "    combos = list(itertools.combinations(cc, 2))\n",
    "    for c in combos:\n",
    "        match_pairs.append(c)\n",
    "#     print(combos)\n",
    "#     print(\"-\"*72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(match_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccmatches = pd.DataFrame(match_pairs)\n",
    "df_ccmatches.columns = [\"entityid1\", \"entityid2\"]\n",
    "df_ccmatches[\"match_string\"] = df_ccmatches.apply(lambda row: str(row[\"entityid1\"])+\"|\"+str(row[\"entityid2\"]), axis=1)\n",
    "df_ccmatches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccmatches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmatches_list = list(df_ccmatches[\"match_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ccmatches = []\n",
    "for m in ccmatches_list:\n",
    "    if m in truth_list:\n",
    "        good_ccmatches.append(\"Good match\")\n",
    "    else:\n",
    "        good_ccmatches.append(\"Bad match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccmatches[\"GoodBad\"] = good_ccmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccmatches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccmatches[\"GoodBad\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccmatches.loc[df_ccmatches[\"GoodBad\"]==\"Bad match\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_good_matches = list(df_ccmatches.loc[df_ccmatches[\"GoodBad\"]==\"Good match\"][\"match_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_good_matches[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_not_found = []\n",
    "for t in truth_list:\n",
    "    if t not in found_good_matches:\n",
    "        truth_not_found.append(t)\n",
    "print(f\"Number of truths not found: {len(truth_not_found)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_not_found[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 3 groups and threshold at 75 (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     221405</li>\n",
    "        <li>Good match     7261</li>\n",
    "        <li>Good/Bad     0.03</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 3 groups and threshold at 80  (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     15725</li>\n",
    "        <li>Good match     4719</li>\n",
    "        <li>Good/Bad     0.3</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 3 groups and threshold at 85  (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     2253</li>\n",
    "        <li>Good match     2706</li>\n",
    "        <li>Good/Bad     1.20</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 10 groups and threshold at 88  (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     666</li>\n",
    "        <li>Good match     2127</li>\n",
    "        <li>Good/Bad     3.19</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 3 groups and threshold at 90  (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     165</li>\n",
    "        <li>Good match     1339</li>\n",
    "        <li>Good/Bad     8.12</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[75,80,85,90]\n",
    "x=[7261,4719,2706,1339]\n",
    "y=[221405,15725,2253,165]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(x=x, y=y)\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "\n",
    "# plt.axis(\"equal\")\n",
    "# plt.xlim(left=0, right=max(y))\n",
    "plt.title(\"Impact of fuzz.ratio threshold on results with 3 groups\")\n",
    "plt.xlabel(\"Good matches\")\n",
    "plt.ylabel(\"Bad matches\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 10 groups and threshold at 90  (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     218</li>\n",
    "        <li>Good match     1608</li>\n",
    "        <li>Good/Bad     7.38</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 10 groups and threshold at 90  (with stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     227</li>\n",
    "        <li>Good match     1499</li>\n",
    "        <li>Good/Bad     6.60</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 10 groups and threshold at 75 and average ratio method (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     945037</li>\n",
    "        <li>Good match     11865</li>\n",
    "        <li>Good/Bad     0.01</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:black; color:white;\">\n",
    "    <h3>Results with 20 groups and threshold at 88 and average ratio method (no stopword removal)</h3>\n",
    "    <hr>\n",
    "    <ul>\n",
    "        <li>Bad match     1788</li>\n",
    "        <li>Good match     2889</li>\n",
    "        <li>Good/Bad     1.62</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
